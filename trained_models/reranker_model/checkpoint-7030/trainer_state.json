{
  "best_global_step": 7030,
  "best_metric": 0.9825889477668432,
  "best_model_checkpoint": "/content/drive/MyDrive/Legal_QA_HRAG_Project/trained_models/reranker_model/checkpoint-7030",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 7030,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03556187766714083,
      "grad_norm": 2.020206928253174,
      "learning_rate": 1.986059743954481e-05,
      "loss": 0.3788,
      "step": 50
    },
    {
      "epoch": 0.07112375533428165,
      "grad_norm": 1.6659140586853027,
      "learning_rate": 1.9721194879089618e-05,
      "loss": 0.1087,
      "step": 100
    },
    {
      "epoch": 0.10668563300142248,
      "grad_norm": 0.16568492352962494,
      "learning_rate": 1.9581792318634426e-05,
      "loss": 0.1138,
      "step": 150
    },
    {
      "epoch": 0.1422475106685633,
      "grad_norm": 0.9958268404006958,
      "learning_rate": 1.9439544807965863e-05,
      "loss": 0.056,
      "step": 200
    },
    {
      "epoch": 0.17780938833570412,
      "grad_norm": 0.09459477663040161,
      "learning_rate": 1.92972972972973e-05,
      "loss": 0.0678,
      "step": 250
    },
    {
      "epoch": 0.21337126600284495,
      "grad_norm": 0.3212241232395172,
      "learning_rate": 1.9155049786628737e-05,
      "loss": 0.0574,
      "step": 300
    },
    {
      "epoch": 0.24893314366998578,
      "grad_norm": 0.13474977016448975,
      "learning_rate": 1.901280227596017e-05,
      "loss": 0.0786,
      "step": 350
    },
    {
      "epoch": 0.2844950213371266,
      "grad_norm": 0.06490954756736755,
      "learning_rate": 1.8870554765291608e-05,
      "loss": 0.029,
      "step": 400
    },
    {
      "epoch": 0.3200568990042674,
      "grad_norm": 0.08491022884845734,
      "learning_rate": 1.8728307254623045e-05,
      "loss": 0.0595,
      "step": 450
    },
    {
      "epoch": 0.35561877667140823,
      "grad_norm": 1.485782265663147,
      "learning_rate": 1.858605974395448e-05,
      "loss": 0.0671,
      "step": 500
    },
    {
      "epoch": 0.3911806543385491,
      "grad_norm": 0.06238475814461708,
      "learning_rate": 1.844381223328592e-05,
      "loss": 0.0441,
      "step": 550
    },
    {
      "epoch": 0.4267425320056899,
      "grad_norm": 0.046486154198646545,
      "learning_rate": 1.8301564722617356e-05,
      "loss": 0.039,
      "step": 600
    },
    {
      "epoch": 0.4623044096728307,
      "grad_norm": 0.07647138833999634,
      "learning_rate": 1.8162162162162164e-05,
      "loss": 0.0708,
      "step": 650
    },
    {
      "epoch": 0.49786628733997157,
      "grad_norm": 0.06724438071250916,
      "learning_rate": 1.80199146514936e-05,
      "loss": 0.05,
      "step": 700
    },
    {
      "epoch": 0.5334281650071123,
      "grad_norm": 1.084905743598938,
      "learning_rate": 1.7877667140825038e-05,
      "loss": 0.0651,
      "step": 750
    },
    {
      "epoch": 0.5689900426742532,
      "grad_norm": 0.03918594494462013,
      "learning_rate": 1.7735419630156475e-05,
      "loss": 0.063,
      "step": 800
    },
    {
      "epoch": 0.604551920341394,
      "grad_norm": 0.03539980202913284,
      "learning_rate": 1.7593172119487912e-05,
      "loss": 0.0338,
      "step": 850
    },
    {
      "epoch": 0.6401137980085349,
      "grad_norm": 0.034480318427085876,
      "learning_rate": 1.7450924608819346e-05,
      "loss": 0.0387,
      "step": 900
    },
    {
      "epoch": 0.6756756756756757,
      "grad_norm": 0.05721038579940796,
      "learning_rate": 1.7308677098150783e-05,
      "loss": 0.0508,
      "step": 950
    },
    {
      "epoch": 0.7112375533428165,
      "grad_norm": 0.02704034373164177,
      "learning_rate": 1.716642958748222e-05,
      "loss": 0.0406,
      "step": 1000
    },
    {
      "epoch": 0.7467994310099573,
      "grad_norm": 0.4360812306404114,
      "learning_rate": 1.7024182076813657e-05,
      "loss": 0.0493,
      "step": 1050
    },
    {
      "epoch": 0.7823613086770982,
      "grad_norm": 0.018564173951745033,
      "learning_rate": 1.6881934566145094e-05,
      "loss": 0.0187,
      "step": 1100
    },
    {
      "epoch": 0.817923186344239,
      "grad_norm": 0.045684341341257095,
      "learning_rate": 1.673968705547653e-05,
      "loss": 0.027,
      "step": 1150
    },
    {
      "epoch": 0.8534850640113798,
      "grad_norm": 0.057882703840732574,
      "learning_rate": 1.6597439544807968e-05,
      "loss": 0.0765,
      "step": 1200
    },
    {
      "epoch": 0.8890469416785206,
      "grad_norm": 0.03127177432179451,
      "learning_rate": 1.6455192034139405e-05,
      "loss": 0.0378,
      "step": 1250
    },
    {
      "epoch": 0.9246088193456614,
      "grad_norm": 0.037733372300863266,
      "learning_rate": 1.6312944523470842e-05,
      "loss": 0.0266,
      "step": 1300
    },
    {
      "epoch": 0.9601706970128022,
      "grad_norm": 0.1509973257780075,
      "learning_rate": 1.6170697012802276e-05,
      "loss": 0.0562,
      "step": 1350
    },
    {
      "epoch": 0.9957325746799431,
      "grad_norm": 1.6870800256729126,
      "learning_rate": 1.6028449502133713e-05,
      "loss": 0.0278,
      "step": 1400
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9896699420508944,
      "eval_f1": 0.9694713328369322,
      "eval_loss": 0.04437858238816261,
      "eval_precision": 0.9545454545454546,
      "eval_recall": 0.9848714069591528,
      "eval_runtime": 5.8741,
      "eval_samples_per_second": 675.673,
      "eval_steps_per_second": 42.389,
      "step": 1406
    },
    {
      "epoch": 1.031294452347084,
      "grad_norm": 0.08811399340629578,
      "learning_rate": 1.588620199146515e-05,
      "loss": 0.0255,
      "step": 1450
    },
    {
      "epoch": 1.0668563300142249,
      "grad_norm": 0.03881405293941498,
      "learning_rate": 1.5743954480796587e-05,
      "loss": 0.0202,
      "step": 1500
    },
    {
      "epoch": 1.1024182076813656,
      "grad_norm": 0.04538187384605408,
      "learning_rate": 1.5601706970128024e-05,
      "loss": 0.0244,
      "step": 1550
    },
    {
      "epoch": 1.1379800853485065,
      "grad_norm": 1.3521851301193237,
      "learning_rate": 1.545945945945946e-05,
      "loss": 0.0314,
      "step": 1600
    },
    {
      "epoch": 1.1735419630156472,
      "grad_norm": 0.016029298305511475,
      "learning_rate": 1.5317211948790898e-05,
      "loss": 0.0131,
      "step": 1650
    },
    {
      "epoch": 1.209103840682788,
      "grad_norm": 1.5231096744537354,
      "learning_rate": 1.5174964438122335e-05,
      "loss": 0.0391,
      "step": 1700
    },
    {
      "epoch": 1.2446657183499288,
      "grad_norm": 0.023076413199305534,
      "learning_rate": 1.503271692745377e-05,
      "loss": 0.0113,
      "step": 1750
    },
    {
      "epoch": 1.2802275960170697,
      "grad_norm": 0.11828555911779404,
      "learning_rate": 1.4890469416785207e-05,
      "loss": 0.0489,
      "step": 1800
    },
    {
      "epoch": 1.3157894736842106,
      "grad_norm": 0.0191151425242424,
      "learning_rate": 1.4748221906116644e-05,
      "loss": 0.0292,
      "step": 1850
    },
    {
      "epoch": 1.3513513513513513,
      "grad_norm": 6.500819683074951,
      "learning_rate": 1.4605974395448081e-05,
      "loss": 0.0419,
      "step": 1900
    },
    {
      "epoch": 1.3869132290184922,
      "grad_norm": 0.02113369293510914,
      "learning_rate": 1.4463726884779517e-05,
      "loss": 0.0334,
      "step": 1950
    },
    {
      "epoch": 1.422475106685633,
      "grad_norm": 0.014073026366531849,
      "learning_rate": 1.4321479374110954e-05,
      "loss": 0.0301,
      "step": 2000
    },
    {
      "epoch": 1.4580369843527738,
      "grad_norm": 0.02375422976911068,
      "learning_rate": 1.417923186344239e-05,
      "loss": 0.0347,
      "step": 2050
    },
    {
      "epoch": 1.4935988620199145,
      "grad_norm": 0.0084593016654253,
      "learning_rate": 1.4036984352773828e-05,
      "loss": 0.0221,
      "step": 2100
    },
    {
      "epoch": 1.5291607396870555,
      "grad_norm": 0.06014307215809822,
      "learning_rate": 1.3894736842105265e-05,
      "loss": 0.0183,
      "step": 2150
    },
    {
      "epoch": 1.5647226173541964,
      "grad_norm": 0.026904169470071793,
      "learning_rate": 1.37524893314367e-05,
      "loss": 0.0286,
      "step": 2200
    },
    {
      "epoch": 1.600284495021337,
      "grad_norm": 0.020344272255897522,
      "learning_rate": 1.3610241820768137e-05,
      "loss": 0.0382,
      "step": 2250
    },
    {
      "epoch": 1.635846372688478,
      "grad_norm": 0.022862538695335388,
      "learning_rate": 1.3467994310099574e-05,
      "loss": 0.0145,
      "step": 2300
    },
    {
      "epoch": 1.671408250355619,
      "grad_norm": 0.015015088953077793,
      "learning_rate": 1.3325746799431011e-05,
      "loss": 0.0283,
      "step": 2350
    },
    {
      "epoch": 1.7069701280227596,
      "grad_norm": 0.01121479831635952,
      "learning_rate": 1.3183499288762447e-05,
      "loss": 0.0137,
      "step": 2400
    },
    {
      "epoch": 1.7425320056899003,
      "grad_norm": 1.7392076253890991,
      "learning_rate": 1.3041251778093884e-05,
      "loss": 0.0087,
      "step": 2450
    },
    {
      "epoch": 1.7780938833570412,
      "grad_norm": 0.4937979280948639,
      "learning_rate": 1.289900426742532e-05,
      "loss": 0.0173,
      "step": 2500
    },
    {
      "epoch": 1.8136557610241821,
      "grad_norm": 0.016221193596720695,
      "learning_rate": 1.2756756756756758e-05,
      "loss": 0.0166,
      "step": 2550
    },
    {
      "epoch": 1.8492176386913228,
      "grad_norm": 0.007899223826825619,
      "learning_rate": 1.2614509246088193e-05,
      "loss": 0.0282,
      "step": 2600
    },
    {
      "epoch": 1.8847795163584637,
      "grad_norm": 0.0055284565314650536,
      "learning_rate": 1.247226173541963e-05,
      "loss": 0.0301,
      "step": 2650
    },
    {
      "epoch": 1.9203413940256047,
      "grad_norm": 0.01189810037612915,
      "learning_rate": 1.2330014224751067e-05,
      "loss": 0.0297,
      "step": 2700
    },
    {
      "epoch": 1.9559032716927454,
      "grad_norm": 0.2801303565502167,
      "learning_rate": 1.2187766714082506e-05,
      "loss": 0.013,
      "step": 2750
    },
    {
      "epoch": 1.991465149359886,
      "grad_norm": 0.00980390515178442,
      "learning_rate": 1.2045519203413943e-05,
      "loss": 0.0458,
      "step": 2800
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9924414210128496,
      "eval_f1": 0.9770642201834863,
      "eval_loss": 0.04137618467211723,
      "eval_precision": 0.9876352395672334,
      "eval_recall": 0.9667170953101362,
      "eval_runtime": 5.764,
      "eval_samples_per_second": 688.582,
      "eval_steps_per_second": 43.199,
      "step": 2812
    },
    {
      "epoch": 2.027027027027027,
      "grad_norm": 0.004688446410000324,
      "learning_rate": 1.1903271692745377e-05,
      "loss": 0.0028,
      "step": 2850
    },
    {
      "epoch": 2.062588904694168,
      "grad_norm": 0.006693506147712469,
      "learning_rate": 1.1761024182076815e-05,
      "loss": 0.0068,
      "step": 2900
    },
    {
      "epoch": 2.0981507823613086,
      "grad_norm": 0.006641052197664976,
      "learning_rate": 1.1618776671408252e-05,
      "loss": 0.0017,
      "step": 2950
    },
    {
      "epoch": 2.1337126600284497,
      "grad_norm": 0.013096888549625874,
      "learning_rate": 1.147652916073969e-05,
      "loss": 0.0229,
      "step": 3000
    },
    {
      "epoch": 2.1692745376955904,
      "grad_norm": 0.004630709532648325,
      "learning_rate": 1.1334281650071125e-05,
      "loss": 0.0099,
      "step": 3050
    },
    {
      "epoch": 2.204836415362731,
      "grad_norm": 0.005973193794488907,
      "learning_rate": 1.1192034139402562e-05,
      "loss": 0.0009,
      "step": 3100
    },
    {
      "epoch": 2.240398293029872,
      "grad_norm": 0.004928275477141142,
      "learning_rate": 1.1049786628733999e-05,
      "loss": 0.0175,
      "step": 3150
    },
    {
      "epoch": 2.275960170697013,
      "grad_norm": 0.004190403502434492,
      "learning_rate": 1.0907539118065436e-05,
      "loss": 0.0077,
      "step": 3200
    },
    {
      "epoch": 2.3115220483641536,
      "grad_norm": 0.0051261973567306995,
      "learning_rate": 1.0765291607396871e-05,
      "loss": 0.0172,
      "step": 3250
    },
    {
      "epoch": 2.3470839260312943,
      "grad_norm": 0.006224298384040594,
      "learning_rate": 1.0623044096728308e-05,
      "loss": 0.0101,
      "step": 3300
    },
    {
      "epoch": 2.382645803698435,
      "grad_norm": 10.122611045837402,
      "learning_rate": 1.0480796586059745e-05,
      "loss": 0.0053,
      "step": 3350
    },
    {
      "epoch": 2.418207681365576,
      "grad_norm": 0.367718368768692,
      "learning_rate": 1.0338549075391182e-05,
      "loss": 0.0221,
      "step": 3400
    },
    {
      "epoch": 2.453769559032717,
      "grad_norm": 0.006742869503796101,
      "learning_rate": 1.0196301564722618e-05,
      "loss": 0.0196,
      "step": 3450
    },
    {
      "epoch": 2.4893314366998576,
      "grad_norm": 0.0032138116657733917,
      "learning_rate": 1.0054054054054055e-05,
      "loss": 0.0006,
      "step": 3500
    },
    {
      "epoch": 2.5248933143669987,
      "grad_norm": 0.0025855572894215584,
      "learning_rate": 9.911806543385492e-06,
      "loss": 0.0002,
      "step": 3550
    },
    {
      "epoch": 2.5604551920341394,
      "grad_norm": 76.32783508300781,
      "learning_rate": 9.769559032716929e-06,
      "loss": 0.0186,
      "step": 3600
    },
    {
      "epoch": 2.59601706970128,
      "grad_norm": 0.06933989375829697,
      "learning_rate": 9.630156472261735e-06,
      "loss": 0.0347,
      "step": 3650
    },
    {
      "epoch": 2.6315789473684212,
      "grad_norm": 0.004238937981426716,
      "learning_rate": 9.487908961593174e-06,
      "loss": 0.0189,
      "step": 3700
    },
    {
      "epoch": 2.667140825035562,
      "grad_norm": 0.0027906291652470827,
      "learning_rate": 9.34566145092461e-06,
      "loss": 0.0103,
      "step": 3750
    },
    {
      "epoch": 2.7027027027027026,
      "grad_norm": 0.025219354778528214,
      "learning_rate": 9.203413940256046e-06,
      "loss": 0.0244,
      "step": 3800
    },
    {
      "epoch": 2.7382645803698438,
      "grad_norm": 0.0037341578863561153,
      "learning_rate": 9.061166429587483e-06,
      "loss": 0.0089,
      "step": 3850
    },
    {
      "epoch": 2.7738264580369845,
      "grad_norm": 0.006385353859513998,
      "learning_rate": 8.91891891891892e-06,
      "loss": 0.009,
      "step": 3900
    },
    {
      "epoch": 2.809388335704125,
      "grad_norm": 35.40800094604492,
      "learning_rate": 8.776671408250357e-06,
      "loss": 0.022,
      "step": 3950
    },
    {
      "epoch": 2.844950213371266,
      "grad_norm": 0.002401467179879546,
      "learning_rate": 8.634423897581793e-06,
      "loss": 0.0134,
      "step": 4000
    },
    {
      "epoch": 2.8805120910384066,
      "grad_norm": 0.0032219572458416224,
      "learning_rate": 8.49217638691323e-06,
      "loss": 0.0345,
      "step": 4050
    },
    {
      "epoch": 2.9160739687055477,
      "grad_norm": 0.009005371481180191,
      "learning_rate": 8.349928876244667e-06,
      "loss": 0.013,
      "step": 4100
    },
    {
      "epoch": 2.9516358463726884,
      "grad_norm": 0.0027026303578168154,
      "learning_rate": 8.207681365576104e-06,
      "loss": 0.0181,
      "step": 4150
    },
    {
      "epoch": 2.987197724039829,
      "grad_norm": 0.002467295154929161,
      "learning_rate": 8.065433854907539e-06,
      "loss": 0.0044,
      "step": 4200
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9929453262786596,
      "eval_f1": 0.9789473684210527,
      "eval_loss": 0.03732460364699364,
      "eval_precision": 0.9730941704035875,
      "eval_recall": 0.9848714069591528,
      "eval_runtime": 5.767,
      "eval_samples_per_second": 688.232,
      "eval_steps_per_second": 43.177,
      "step": 4218
    },
    {
      "epoch": 3.0227596017069702,
      "grad_norm": 0.003589279018342495,
      "learning_rate": 7.923186344238976e-06,
      "loss": 0.0059,
      "step": 4250
    },
    {
      "epoch": 3.058321479374111,
      "grad_norm": 0.0037546439561992884,
      "learning_rate": 7.780938833570413e-06,
      "loss": 0.0072,
      "step": 4300
    },
    {
      "epoch": 3.0938833570412516,
      "grad_norm": 0.0029917594511061907,
      "learning_rate": 7.63869132290185e-06,
      "loss": 0.0041,
      "step": 4350
    },
    {
      "epoch": 3.1294452347083928,
      "grad_norm": 0.022534053772687912,
      "learning_rate": 7.4964438122332865e-06,
      "loss": 0.0006,
      "step": 4400
    },
    {
      "epoch": 3.1650071123755334,
      "grad_norm": 0.002144336001947522,
      "learning_rate": 7.3541963015647235e-06,
      "loss": 0.0002,
      "step": 4450
    },
    {
      "epoch": 3.200568990042674,
      "grad_norm": 0.1336914300918579,
      "learning_rate": 7.21194879089616e-06,
      "loss": 0.0002,
      "step": 4500
    },
    {
      "epoch": 3.2361308677098153,
      "grad_norm": 0.0024347729049623013,
      "learning_rate": 7.069701280227597e-06,
      "loss": 0.0149,
      "step": 4550
    },
    {
      "epoch": 3.271692745376956,
      "grad_norm": 0.12364551424980164,
      "learning_rate": 6.927453769559034e-06,
      "loss": 0.0003,
      "step": 4600
    },
    {
      "epoch": 3.3072546230440967,
      "grad_norm": 0.002191536594182253,
      "learning_rate": 6.78520625889047e-06,
      "loss": 0.0001,
      "step": 4650
    },
    {
      "epoch": 3.3428165007112374,
      "grad_norm": 0.0015833232318982482,
      "learning_rate": 6.642958748221907e-06,
      "loss": 0.0001,
      "step": 4700
    },
    {
      "epoch": 3.3783783783783785,
      "grad_norm": 0.001750171184539795,
      "learning_rate": 6.500711237553343e-06,
      "loss": 0.0001,
      "step": 4750
    },
    {
      "epoch": 3.413940256045519,
      "grad_norm": 0.001860518241301179,
      "learning_rate": 6.35846372688478e-06,
      "loss": 0.0002,
      "step": 4800
    },
    {
      "epoch": 3.44950213371266,
      "grad_norm": 0.001943189068697393,
      "learning_rate": 6.2162162162162164e-06,
      "loss": 0.0088,
      "step": 4850
    },
    {
      "epoch": 3.485064011379801,
      "grad_norm": 0.2662465572357178,
      "learning_rate": 6.0739687055476535e-06,
      "loss": 0.0242,
      "step": 4900
    },
    {
      "epoch": 3.5206258890469417,
      "grad_norm": 0.002166874473914504,
      "learning_rate": 5.93172119487909e-06,
      "loss": 0.002,
      "step": 4950
    },
    {
      "epoch": 3.5561877667140824,
      "grad_norm": 0.001894479151815176,
      "learning_rate": 5.789473684210527e-06,
      "loss": 0.0001,
      "step": 5000
    },
    {
      "epoch": 3.591749644381223,
      "grad_norm": 0.002495557302609086,
      "learning_rate": 5.647226173541963e-06,
      "loss": 0.0071,
      "step": 5050
    },
    {
      "epoch": 3.6273115220483643,
      "grad_norm": 0.0012706967536360025,
      "learning_rate": 5.5049786628734e-06,
      "loss": 0.0004,
      "step": 5100
    },
    {
      "epoch": 3.662873399715505,
      "grad_norm": 0.0016109510324895382,
      "learning_rate": 5.362731152204836e-06,
      "loss": 0.019,
      "step": 5150
    },
    {
      "epoch": 3.6984352773826457,
      "grad_norm": 0.0024119913578033447,
      "learning_rate": 5.220483641536274e-06,
      "loss": 0.0137,
      "step": 5200
    },
    {
      "epoch": 3.733997155049787,
      "grad_norm": 0.02983335591852665,
      "learning_rate": 5.078236130867709e-06,
      "loss": 0.0002,
      "step": 5250
    },
    {
      "epoch": 3.7695590327169275,
      "grad_norm": 0.0019076113821938634,
      "learning_rate": 4.935988620199147e-06,
      "loss": 0.0043,
      "step": 5300
    },
    {
      "epoch": 3.805120910384068,
      "grad_norm": 0.018728751689195633,
      "learning_rate": 4.7937411095305834e-06,
      "loss": 0.0053,
      "step": 5350
    },
    {
      "epoch": 3.8406827880512093,
      "grad_norm": 0.06044098734855652,
      "learning_rate": 4.6514935988620205e-06,
      "loss": 0.0101,
      "step": 5400
    },
    {
      "epoch": 3.87624466571835,
      "grad_norm": 0.0015467158518731594,
      "learning_rate": 4.509246088193457e-06,
      "loss": 0.0053,
      "step": 5450
    },
    {
      "epoch": 3.9118065433854907,
      "grad_norm": 0.0016548960702493787,
      "learning_rate": 4.366998577524894e-06,
      "loss": 0.0006,
      "step": 5500
    },
    {
      "epoch": 3.9473684210526314,
      "grad_norm": 0.002398025244474411,
      "learning_rate": 4.22475106685633e-06,
      "loss": 0.0001,
      "step": 5550
    },
    {
      "epoch": 3.9829302987197726,
      "grad_norm": 0.0014514160575345159,
      "learning_rate": 4.082503556187767e-06,
      "loss": 0.0157,
      "step": 5600
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9937011841773746,
      "eval_f1": 0.9810174639331815,
      "eval_loss": 0.043892357498407364,
      "eval_precision": 0.9847560975609756,
      "eval_recall": 0.9773071104387292,
      "eval_runtime": 5.7551,
      "eval_samples_per_second": 689.649,
      "eval_steps_per_second": 43.266,
      "step": 5624
    },
    {
      "epoch": 4.018492176386913,
      "grad_norm": 0.0019248867174610496,
      "learning_rate": 3.940256045519203e-06,
      "loss": 0.0083,
      "step": 5650
    },
    {
      "epoch": 4.054054054054054,
      "grad_norm": 0.0014051322359591722,
      "learning_rate": 3.7980085348506406e-06,
      "loss": 0.0001,
      "step": 5700
    },
    {
      "epoch": 4.089615931721195,
      "grad_norm": 0.830872118473053,
      "learning_rate": 3.6557610241820772e-06,
      "loss": 0.0001,
      "step": 5750
    },
    {
      "epoch": 4.125177809388336,
      "grad_norm": 0.0017470009624958038,
      "learning_rate": 3.513513513513514e-06,
      "loss": 0.0001,
      "step": 5800
    },
    {
      "epoch": 4.160739687055477,
      "grad_norm": 0.0009899595752358437,
      "learning_rate": 3.3712660028449505e-06,
      "loss": 0.0001,
      "step": 5850
    },
    {
      "epoch": 4.196301564722617,
      "grad_norm": 0.0011015613563358784,
      "learning_rate": 3.2290184921763875e-06,
      "loss": 0.0003,
      "step": 5900
    },
    {
      "epoch": 4.231863442389758,
      "grad_norm": 0.0011541707208380103,
      "learning_rate": 3.086770981507824e-06,
      "loss": 0.0001,
      "step": 5950
    },
    {
      "epoch": 4.2674253200568995,
      "grad_norm": 0.0016268957406282425,
      "learning_rate": 2.9445234708392607e-06,
      "loss": 0.0005,
      "step": 6000
    },
    {
      "epoch": 4.30298719772404,
      "grad_norm": 0.0012104925699532032,
      "learning_rate": 2.8022759601706973e-06,
      "loss": 0.0001,
      "step": 6050
    },
    {
      "epoch": 4.338549075391181,
      "grad_norm": 0.0011796025792136788,
      "learning_rate": 2.660028449502134e-06,
      "loss": 0.0041,
      "step": 6100
    },
    {
      "epoch": 4.374110953058321,
      "grad_norm": 0.0014319003093987703,
      "learning_rate": 2.5177809388335706e-06,
      "loss": 0.0041,
      "step": 6150
    },
    {
      "epoch": 4.409672830725462,
      "grad_norm": 0.0014893516199663281,
      "learning_rate": 2.375533428165007e-06,
      "loss": 0.0001,
      "step": 6200
    },
    {
      "epoch": 4.445234708392603,
      "grad_norm": 0.0013379233423620462,
      "learning_rate": 2.2332859174964442e-06,
      "loss": 0.0125,
      "step": 6250
    },
    {
      "epoch": 4.480796586059744,
      "grad_norm": 0.000951239897403866,
      "learning_rate": 2.091038406827881e-06,
      "loss": 0.0001,
      "step": 6300
    },
    {
      "epoch": 4.516358463726885,
      "grad_norm": 0.0013625383144244552,
      "learning_rate": 1.9487908961593175e-06,
      "loss": 0.0001,
      "step": 6350
    },
    {
      "epoch": 4.551920341394026,
      "grad_norm": 0.0023076410870999098,
      "learning_rate": 1.806543385490754e-06,
      "loss": 0.0115,
      "step": 6400
    },
    {
      "epoch": 4.587482219061166,
      "grad_norm": 0.0012994942953810096,
      "learning_rate": 1.6642958748221907e-06,
      "loss": 0.0001,
      "step": 6450
    },
    {
      "epoch": 4.623044096728307,
      "grad_norm": 0.0014612877275794744,
      "learning_rate": 1.5220483641536273e-06,
      "loss": 0.0001,
      "step": 6500
    },
    {
      "epoch": 4.658605974395448,
      "grad_norm": 0.0013408907689154148,
      "learning_rate": 1.3798008534850641e-06,
      "loss": 0.0003,
      "step": 6550
    },
    {
      "epoch": 4.694167852062589,
      "grad_norm": 0.0011552845826372504,
      "learning_rate": 1.2375533428165008e-06,
      "loss": 0.0046,
      "step": 6600
    },
    {
      "epoch": 4.72972972972973,
      "grad_norm": 0.001221273560076952,
      "learning_rate": 1.0953058321479376e-06,
      "loss": 0.0048,
      "step": 6650
    },
    {
      "epoch": 4.76529160739687,
      "grad_norm": 0.0013782944297417998,
      "learning_rate": 9.530583214793741e-07,
      "loss": 0.0001,
      "step": 6700
    },
    {
      "epoch": 4.800853485064011,
      "grad_norm": 0.0008572625229135156,
      "learning_rate": 8.108108108108109e-07,
      "loss": 0.0044,
      "step": 6750
    },
    {
      "epoch": 4.836415362731152,
      "grad_norm": 0.001495907548815012,
      "learning_rate": 6.685633001422475e-07,
      "loss": 0.0001,
      "step": 6800
    },
    {
      "epoch": 4.871977240398293,
      "grad_norm": 0.0013062565121799707,
      "learning_rate": 5.263157894736843e-07,
      "loss": 0.0068,
      "step": 6850
    },
    {
      "epoch": 4.907539118065434,
      "grad_norm": 0.0010250674095004797,
      "learning_rate": 3.8406827880512093e-07,
      "loss": 0.0001,
      "step": 6900
    },
    {
      "epoch": 4.943100995732575,
      "grad_norm": 0.0013514934107661247,
      "learning_rate": 2.4182076813655766e-07,
      "loss": 0.0001,
      "step": 6950
    },
    {
      "epoch": 4.978662873399715,
      "grad_norm": 0.0013481093337759376,
      "learning_rate": 9.957325746799431e-08,
      "loss": 0.0077,
      "step": 7000
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9942050894431846,
      "eval_f1": 0.9825889477668432,
      "eval_loss": 0.04526819661259651,
      "eval_precision": 0.9833333333333333,
      "eval_recall": 0.9818456883509834,
      "eval_runtime": 5.7481,
      "eval_samples_per_second": 690.491,
      "eval_steps_per_second": 43.319,
      "step": 7030
    }
  ],
  "logging_steps": 50,
  "max_steps": 7030,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.9580260398848e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
